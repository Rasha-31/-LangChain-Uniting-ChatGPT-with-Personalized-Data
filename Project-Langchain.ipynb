{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8353cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4374c7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ed8ed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d314b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "text = \"what is the capital of india?\"\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25040d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The current weather in Jodhpur is mostly sunny with a high of around 97 degrees Fahrenheit (36 degrees Celsius) and a low of around 72 degrees Fahrenheit (22 degrees Celsius).\n"
     ]
    }
   ],
   "source": [
    "text = \"What is the weather today in jodhpur\"\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d1ed566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "\n",
      "The objectives of langChain are to provide a platform for users to learn languages, connect with language exchange partners, teach and take classes, participate in language events, and create content on language-related topics. In addition, langChain aims to make language learning more accessible, interactive, and engaging. The platform also allows users to share their experiences with each other.\n"
     ]
    }
   ],
   "source": [
    "text = \"What are the objectives of langChain\"\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c254900",
   "metadata": {},
   "source": [
    "# Prompt Templates: Manage prompts for LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b0564d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db421b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=['food'],\n",
    "    template=\"What are 5 vacation destinations in India for someone who likes to eat {food}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "107ad922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are 5 vacation destinations in India for someone who likes to eat dessert?\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(food=\"dessert\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2e800336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Jaipur, Rajasthan – Famous for its delicious traditional sweets such as ghevar, moong dal halwa, and ghewar\n",
      "2. Delhi – Wide selection of Indian desserts including gulab jamun, jalebi, laddu, and rasmalai\n",
      "3. Varanasi, Uttar Pradesh – Famous for its traditional sweets, like balushahi and malaiyo\n",
      "4. Agra, Uttar Pradesh – Home to the famous petha, a dessert made from sugar and squash\n",
      "5. Goa – Sample popular Indian desserts like doce, bebinca, dodol, and doce de leite at one of the many Portuguese-styled cafes in the area.\n"
     ]
    }
   ],
   "source": [
    "print(llm(prompt.format(food=\"dessert\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7702f1c",
   "metadata": {},
   "source": [
    "# Chains: Combine LLMs and prompts in multi-step workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "47fb2633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b26868e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['food'],\n",
    "    template=\"What are 5 vacation destinations in India for someone who likes to eat {food}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7bfe6ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2d53b336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Coorg, Karnataka: Coorg is known as the Scotland of India and is home to plenty of exotic fruits like rambutan, jambul, rose apple, and guava.\n",
      "\n",
      "2. Andaman & Nicobar Islands: These islands are known for their sweet pineapple, mango, papaya, and jackfruit.\n",
      "\n",
      "3. Ooty, Tamil Nadu: This hill station is surrounded by lush, green tea plantations, and offers a variety of juicy fruits like oranges, apples, pineapple, grapes, and pears.\n",
      "\n",
      "4. Shillong, Meghalaya: This city is blessed with an abundance of fruits like oranges, bananas, apples, raspberries, and apricots.\n",
      "\n",
      "5.Gulmarg, Jammu & Kashmir: Visitors to this picturesque town can enjoy the sweet and tart flavors of apricots, plums, almonds, pears, and apples.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"fruit\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e067ec",
   "metadata": {},
   "source": [
    "# Agents: Dynamically call chains based on user inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cbdd2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a18b9015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "139d99cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the model\n",
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e6cbe2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in some tools to use\n",
    "\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"619d57df6cb3124cb533a1a87bbc40b6420157bc3acf6a8b80a72ccbad700f6e\"\n",
    "\n",
    "tools = load_tools([\"serpapi\",\"llm-math\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cf711682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, let's initialize an agent with:\n",
    "# 1. The tools\n",
    "# 2. The language model\n",
    "# 3. The type of agent we want to use.\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c952551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out who the current president is and how they are elected.\n",
      "Action: Search\n",
      "Action Input: \"current president of India\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mDroupadi Murmu\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find out how they are elected\n",
      "Action: Search\n",
      "Action Input: \"how is the president of India elected\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mWho elects the President of India? Ans. The President is elected by the members of an electoral college consisting of the elected members of both the Houses of Parliament and the elected members of the Legislative Assemblies of States and the Union Territories of Delhi and Pondicherry.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The current president of India is Droupadi Murmu and they are elected by the members of an electoral college consisting of the elected members of both the Houses of Parliament and the elected members of the Legislative Assemblies of States and the Union Territories of Delhi and Pondicherry.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current president of India is Droupadi Murmu and they are elected by the members of an electoral college consisting of the elected members of both the Houses of Parliament and the elected members of the Legislative Assemblies of States and the Union Territories of Delhi and Pondicherry.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's test it out:\n",
    "agent.run(\"Who is the current president of India? How someone gets elected as a president in India?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500f528c",
   "metadata": {},
   "source": [
    "# Memory: Add state to chains and agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f7a88731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d637d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b50c362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hi there! It's nice to meet you. How can I help you today?\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b750bae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: I'm doing well! Just having a conversation with an AI.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"I'm doing well! Just having a conversation with an AI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d878f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: I'm doing well! Just having a conversation with an AI.\n",
      "AI:  That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\n",
      "Human: What was the first thing I said to you?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' You said \"Hi there!\"'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What was the first thing I said to you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44b3ef90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: I'm doing well! Just having a conversation with an AI.\n",
      "AI:  That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\n",
      "Human: What was the first thing I said to you?\n",
      "AI:  You said \"Hi there!\"\n",
      "Human: What is an alternative phrase for the first thing i said to you?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' An alternative phrase for the first thing you said to me could be \"Greetings!\"'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is an alternative phrase for the first thing i said to you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e4b3e7",
   "metadata": {},
   "source": [
    "#  Asking questions on your Custom (or Private) Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a730e54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install python-magic\n",
    "#pip install chromadb\n",
    "#pip install hnswlib --user\n",
    "#pip install tiktoken\n",
    "#pip install constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8985128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\rasha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import OpenAI, VectorDBQA\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "import magic\n",
    "import os\n",
    "import nltk\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35744f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./LangChain-Documentation.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='With the recent advancements in technology, there has been an ever-increasing rise in online platforms that are based on Artificial Intelligence. These platforms, such as OpenAI’s ChatGPT, have started a new wave in the world. Just type in a few words and you’ll get an entire database of factual information in one place. You don’t need to do a lot of research like in earlier days. This technology has been useful for students, teachers, digital marketers, content writers, and many more. No wonder that with its release in 2022, it has gained high popularity among the youth and working professionals.\\n\\nMoving back a few years, ChatGPT came into the picture because of GPT-3, which is a Large Language Model or LLM released in 2020. To sum up, based on GPT-3, ChatGPT was created. But what is the technology behind GPT-3? Well, it’s simple, it is a Large Language Model that uses deep learning methods to produce human-like content.\\n\\nHowever, it cannot be ignored that it was through ChatGPT that interest in Large Language Models reached the sky. After all, it opened up new doors for everyone around the world. Indeed, LLMs and generative AI weren’t that popular when they were released but after ChatGPT people started showing their interest in this technology. As a result, there have been significant advances in LLMs.\\n\\nHistorically, it all started with the release of Google’s “sentient” LaMDA. After that, the first open-source LLM “BLOOM” was released. And then OpenAI released their next-generation text embedding GPT 3.5 models. Finally, with these giant leaps in the LLM world, OpenAI released ChatGPT – which directly put LLM into the spotlight.\\n\\nAround the same time, the LLM wave ushered to the shore another useful framework, which came to be known by the name LangChain. LangChain was released by its creator Harrison Chase in the fall of October 2022.\\n\\nLangChain is an intuitive open-source framework created to simplify the development of applications using large language models (LLMs), such as OpenAI or Hugging Face. This allows you to build dynamic, data-responsive applications that harness the most recent breakthroughs in natural language processing.\\n\\nWhat is LangChain? In this article, we will cover the key features of LangChain, including its AI capabilities, the types of data sources it can connect with, and the range of NLP solutions it can offer. We’ll also dive into some potential use cases for LangChain, from sentiment analysis to chatbots and beyond.\\n\\nWhether you’re a developer, a data scientist, or simply curious about the latest developments in NLP technology, this article is for you. So, if you want to learn more about LangChain and how it can help you unlock the power of language in your business or organization, keep reading!\\n\\nTable of Contents What is LangChain? LangChain is a powerful, open-source framework designed to help you develop applications powered by a language model, particularly a large language model (LLM).\\n\\nIt goes beyond standard API calls by being data-aware and agentic, enabling connections with various data sources for richer, personalized experiences. It can also empower a language model to interact dynamically with its environment.\\n\\nLangChain streamlines the development of diverse applications, such as chatbots, Generative Question-Answering (GQA), and summarization. By “chaining” components from multiple modules, it allows for the creation of unique applications built around an LLM.\\n\\nNow that you understand what LangChain is and why it is important, let’s explore the core components of LangChain in the next section.\\n\\nWhat are the Core Components of LangChain? To be able to fully interpret the workings of LangChain, it is important to understand it’s core components.\\n\\nThis section covers the primary aspects of LangChain: language models and APIs, framework and libraries, and documentation and modules.\\n\\nLet’s get into it!\\n\\nCore Components of LangChain on a computer screen 1. Large Language Models and APIs LangChain supports language models, including those from prominent AI platforms like OpenAI, which is the company behind the revolutionary chatbot ChatGPT. These models are the foundation for creating powerful, language-driven applications.\\n\\nLangChain provides an application programming interface (APIs) to access and interact with them and facilitate seamless integration, allowing you to harness the full potential of LLMs for various use cases.\\n\\nA laptop showing language models and APIs of LangChain For example, you can create a chatbot that generates personalized travel itineraries based on user’s interests and past experiences.\\n\\n2. Framework and Libraries The LangChain framework consists of an array of tools, components, and interfaces that simplify the development process for language model-powered applications.\\n\\nIt offers Python libraries to help streamline rich, data-driven interactions with the AI models by chaining different components together.\\n\\nLangChain library and framework Some advantages of the LangChain framework include the following:\\n\\nEfficient integration with popular AI platforms such as OpenAI and Hugging Face\\n\\nAccess to language-driven data-aware applications by connecting the models to other data sources\\n\\nAgility through enabling a language model to interact dynamically with their environment\\n\\n3. Documentation and Modules To make it easier for you to develop applications using LangChain, the framework has extensive documentation.\\n\\nDocumentations and Modules for LangChain This guide covers different aspects of development, such as:\\n\\nSetting up your development environment Integrating preferred AI models Creating advanced use cases supported by LangChain In addition, modular construction facilitates high levels of customization for your applications. You can choose and combine modules according to your needs, further enhancing LangChain’s versatility.\\n\\nInstallation and Setup of LangChain To start using LangChain in your project, first ensure Python is installed on your system. LangChain can be effortlessly installed with pip, Python’s default package manager.\\n\\nSimply open your terminal or command prompt and enter:\\n\\npip install langchain This command installs LangChain and its required dependencies in your Python environment. Now, you’re ready to harness the power of LangChain for language model-driven applications.\\n\\nThroughout your project, you may need to connect LangChain with various model providers, data stores, and APIs. For instance, to utilize OpenAI’s APIs, install their SDK:\\n\\npip install openai After installing the OpenAI SDK, you can connect it with LangChain by following these steps:\\n\\nStep 1: Obtain an API key from the OpenAI platform. Sign up or log in to your account on the OpenAI website, then navigate to the API Keys section.\\n\\nClick on Create New Secret Key.\\n\\nCreate a new API key to get your API for using ChatGPT Give your key a unique name and click Create New Key.\\n\\nNaming and Saivng the API Key Now you can copy your newly generated secret key and use it in your applications.\\n\\nCopy the API Key and use it for your applications Step 2: Set up the OpenAI API key as an environment variable in your project to ensures secure access without hardcoding the key in your code. For example, in a .env file, add the following line: OPENAI_API_KEY=your_api_key_here Step 3: In your Python script, import the necessary libraries and load the environment variable: import os from dotenv import load_dotenv import openai import langchain\\n\\nload_dotenv() openai.api_key = os.getenv(\"OPENAI_API_KEY\") Importing OpenAI\\'s and LangChain\\'s libraries and environment variables Step 4: Now, you can use LangChain to interact with the OpenAI API. For example, to generate a text response using GPT-3: response = langchain.generate_text(prompt=\"What are the benefits of using LangChain? \", model=\"openai/gpt-3\") print(response) Response generation using LangChain through ChatGPT Now that you know how to set up your development environment using the OpenAI API key, we take at how you can develop apps using LangChain in the next section.\\n\\nHow to Develop Applications with LangChain LangChain is an open-source framework designed for developing applications powered by a language model.\\n\\nYou can utilize its capabilities to build powerful applications that make use of AI models like ChatGPT while integrating with external sources such as Google Drive, Notion, and Wikipedia.\\n\\nDeveloping applications with LangChain Developing applications with LangChain is a straightforward process that involves the following steps.\\n\\nDefine your use case: First, you need to define your use case and requirements, which will help you select the appropriate components and LLMs to use. Build the logic: Next, you can use LangChain’s flexible prompts and chains to build the logic of your application. You can also use LangChain’s code to create custom functionality tailored to your use case. Once you have built the application’s logic, you can use LangChain’s components to add specific features, such as data extraction or language translation. Set and manipulate context: Finally, you can set and manipulate context to guide your application’s behavior and improve its performance. With LangChain, you have the power to create highly customized and feature-rich applications using LLMs with ease. The above should give you a basic understanding of how to develop applications using LangChain. In the next section, we’ll explore the different applications that find extensive use cases for LangChain.\\n\\n3 Application Examples of LangChain LangChain allows you to build advanced applications using a large language model (LLM). With its flexibility, customization options, and powerful components, LangChain can be used to create a wide variety of applications across different industries.\\n\\nPython engineers going over applications of LangChain The following are some of the examples where LangChain is extensively used:\\n\\n1. Text Summarization (Data Augmented Generation) With LangChain, you can develop applications that handle text summarization tasks efficiently.\\n\\nBy leveraging powerful language models like ChatGPT, your application will be able to generate accurate and concise summaries of large texts, allowing your users to quickly grasp the main points of complex documents.\\n\\n2. Question Answering Another use case for LangChain is building applications that provide question answering capabilities.\\n\\nBy integrating with a large language model, your application can receive user-inputted text data and extract relevant answers from a variety of sources, such as Wikipedia, Notion, or Apify Actors. This functionality can be beneficial for users seeking quick and reliable information on different topics.\\n\\n3. Chatbots (Language Model) LangChain is a valuable tool for creating chatbots powered by language models. By taking advantage of LangChain’s framework and components, your chatbot applications can provide a more natural and engaging user experience.\\n\\nUsers can interact with your chatbots for general conversation, support inquiries, or other specific purposes, and the language model will generate context-aware responses.\\n\\nThese application examples are just a few ways in which you can utilize LangChain to build powerful and versatile applications. By understanding the strengths of language models, you can create innovative solutions that cater to the needs of your users.\\n\\nTo see an example application of building applications with Python, check the following video out:\\n\\nWhat are Integrations in LangChain? LangChain provides end-to-end chains integration to make working with various programming languages, platforms, and data sources easier for you.\\n\\nThis ensures that you can seamlessly build applications utilizing a language model in the environment of your choice.\\n\\nPossible integrations in LangChain In terms of programming languages, LangChain provides support for both JavaScript and TypeScript, you can leverage the power of LangChain in web-based and Node.js applications and take advantage of the robust type-safety features TypeScript provides.\\n\\nHere’s a short list of key integrations LangChain has to offer:\\n\\nLarge Language Models (LLMs): OpenAI, Hugging Face, Anthropic, and more.\\n\\nCloud Platforms: Azure, Amazon, Google Cloud, and other popular cloud providers\\n\\nData Sources: Google Drive, Notion, Wikipedia, Apify Actors, and more.\\n\\nBy utilizing these integrations, you can create more advanced and versatile applications centered around a language model.\\n\\nThis will help you develop and deploy your projects quickly and efficiently, leveraging the right tools and resources for your needs.\\n\\nAdvanced Features and Customization of LangChain LangChain offers advanced features and customization options for creating powerful applications using LLMs.\\n\\nYou can tailor your application’s behavior and build sophisticated use cases such as Generative Question-Answering (GQA) or chatbots.\\n\\nLaptop showing advanced features and customization of LangChain The following are some of the key features of LangChain:\\n\\nCustomizable prompts to suit your needs Building chain link components for advanced use cases Code customization for developing unique applications Model integration for data augmented generation and accessing high-quality language model application like text-davinci-003 Flexible components to mix and match components for specific requirements Context manipulation to set and guide context for improved accuracy and user experience With LangChain, you can create feature-rich applications that stand out from the crowd, thanks to its advanced customization options.\\n\\nTo help you take full advantage of LangChain’s features, let’s take a look at some valuable resources you could use in the next section!\\n\\nResources and Support for LangChain LangChain comes with various resources and support to help you develop powerful language model-powered applications.\\n\\nPython engineers sharing resources and support for LangChain Following are some of the key resources that you can use when working with LangChain:\\n\\nAI Libraries such as OpenAI and Hugging Face for AI models External sources such as Notion, Wikipedia, and Google Drive for targeted data LangChain documentation for guides on connecting and chaining components Official Documentation GitHub Repository PyPI Package Repository Data augmentation to improve context-aware results through external data sources, indexing, and vector representations Lastly, engaging with the LangChain community and dedicated support slack channel can be beneficial if you encounter challenges or want to learn from others’ experiences. From forums to online groups, connecting with fellow developers will enrich your journey with LangChain.\\n\\nFinal Thoughts LangChain offers a comprehensive approach to developing applications powered by generative models and LLMs. By integrating core concepts from data science, developers can leverage multiple components, prompt templates, and vector databases to create innovative solutions beyond traditional metrics.\\n\\nAs technology evolves, agents involve more sophisticated elements, including chat interfaces, offering more comprehensive support in various use cases.\\n\\nWhether you’re developing chatbots, sentiment analysis tools, or any other NLP application, LangChain can help you unlock the full potential of your data. As NLP technology continues to evolve and grow in importance, platforms like LangChain will only become more valuable.\\n\\nSo, if you’re looking to stay ahead of the curve in the world of NLP, be sure to check out LangChain and see what it can do for you!', metadata={'source': './LangChain-Documentation.txt'})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "\n",
    "def file_loader(path):\n",
    "    return UnstructuredFileLoader(path)\n",
    "\n",
    "# loader = file_loader(\"./LangChain-Documentation.txt\") \n",
    "loader = file_loader(input())\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5368ebfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=2000, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf44ac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06094876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='With the recent advancements in technology, there has been an ever-increasing rise in online platforms that are based on Artificial Intelligence. These platforms, such as OpenAI’s ChatGPT, have started a new wave in the world. Just type in a few words and you’ll get an entire database of factual information in one place. You don’t need to do a lot of research like in earlier days. This technology has been useful for students, teachers, digital marketers, content writers, and many more. No wonder that with its release in 2022, it has gained high popularity among the youth and working professionals.\\n\\nMoving back a few years, ChatGPT came into the picture because of GPT-3, which is a Large Language Model or LLM released in 2020. To sum up, based on GPT-3, ChatGPT was created. But what is the technology behind GPT-3? Well, it’s simple, it is a Large Language Model that uses deep learning methods to produce human-like content.\\n\\nHowever, it cannot be ignored that it was through ChatGPT that interest in Large Language Models reached the sky. After all, it opened up new doors for everyone around the world. Indeed, LLMs and generative AI weren’t that popular when they were released but after ChatGPT people started showing their interest in this technology. As a result, there have been significant advances in LLMs.\\n\\nHistorically, it all started with the release of Google’s “sentient” LaMDA. After that, the first open-source LLM “BLOOM” was released. And then OpenAI released their next-generation text embedding GPT 3.5 models. Finally, with these giant leaps in the LLM world, OpenAI released ChatGPT – which directly put LLM into the spotlight.\\n\\nAround the same time, the LLM wave ushered to the shore another useful framework, which came to be known by the name LangChain. LangChain was released by its creator Harrison Chase in the fall of October 2022.', metadata={'source': './LangChain-Documentation.txt'}),\n",
       " Document(page_content='LangChain is an intuitive open-source framework created to simplify the development of applications using large language models (LLMs), such as OpenAI or Hugging Face. This allows you to build dynamic, data-responsive applications that harness the most recent breakthroughs in natural language processing.\\n\\nWhat is LangChain? In this article, we will cover the key features of LangChain, including its AI capabilities, the types of data sources it can connect with, and the range of NLP solutions it can offer. We’ll also dive into some potential use cases for LangChain, from sentiment analysis to chatbots and beyond.\\n\\nWhether you’re a developer, a data scientist, or simply curious about the latest developments in NLP technology, this article is for you. So, if you want to learn more about LangChain and how it can help you unlock the power of language in your business or organization, keep reading!\\n\\nTable of Contents What is LangChain? LangChain is a powerful, open-source framework designed to help you develop applications powered by a language model, particularly a large language model (LLM).\\n\\nIt goes beyond standard API calls by being data-aware and agentic, enabling connections with various data sources for richer, personalized experiences. It can also empower a language model to interact dynamically with its environment.\\n\\nLangChain streamlines the development of diverse applications, such as chatbots, Generative Question-Answering (GQA), and summarization. By “chaining” components from multiple modules, it allows for the creation of unique applications built around an LLM.\\n\\nNow that you understand what LangChain is and why it is important, let’s explore the core components of LangChain in the next section.\\n\\nWhat are the Core Components of LangChain? To be able to fully interpret the workings of LangChain, it is important to understand it’s core components.', metadata={'source': './LangChain-Documentation.txt'}),\n",
       " Document(page_content='This section covers the primary aspects of LangChain: language models and APIs, framework and libraries, and documentation and modules.\\n\\nLet’s get into it!\\n\\nCore Components of LangChain on a computer screen 1. Large Language Models and APIs LangChain supports language models, including those from prominent AI platforms like OpenAI, which is the company behind the revolutionary chatbot ChatGPT. These models are the foundation for creating powerful, language-driven applications.\\n\\nLangChain provides an application programming interface (APIs) to access and interact with them and facilitate seamless integration, allowing you to harness the full potential of LLMs for various use cases.\\n\\nA laptop showing language models and APIs of LangChain For example, you can create a chatbot that generates personalized travel itineraries based on user’s interests and past experiences.\\n\\n2. Framework and Libraries The LangChain framework consists of an array of tools, components, and interfaces that simplify the development process for language model-powered applications.\\n\\nIt offers Python libraries to help streamline rich, data-driven interactions with the AI models by chaining different components together.\\n\\nLangChain library and framework Some advantages of the LangChain framework include the following:\\n\\nEfficient integration with popular AI platforms such as OpenAI and Hugging Face\\n\\nAccess to language-driven data-aware applications by connecting the models to other data sources\\n\\nAgility through enabling a language model to interact dynamically with their environment\\n\\n3. Documentation and Modules To make it easier for you to develop applications using LangChain, the framework has extensive documentation.\\n\\nDocumentations and Modules for LangChain This guide covers different aspects of development, such as:', metadata={'source': './LangChain-Documentation.txt'}),\n",
       " Document(page_content='Setting up your development environment Integrating preferred AI models Creating advanced use cases supported by LangChain In addition, modular construction facilitates high levels of customization for your applications. You can choose and combine modules according to your needs, further enhancing LangChain’s versatility.\\n\\nInstallation and Setup of LangChain To start using LangChain in your project, first ensure Python is installed on your system. LangChain can be effortlessly installed with pip, Python’s default package manager.\\n\\nSimply open your terminal or command prompt and enter:\\n\\npip install langchain This command installs LangChain and its required dependencies in your Python environment. Now, you’re ready to harness the power of LangChain for language model-driven applications.\\n\\nThroughout your project, you may need to connect LangChain with various model providers, data stores, and APIs. For instance, to utilize OpenAI’s APIs, install their SDK:\\n\\npip install openai After installing the OpenAI SDK, you can connect it with LangChain by following these steps:\\n\\nStep 1: Obtain an API key from the OpenAI platform. Sign up or log in to your account on the OpenAI website, then navigate to the API Keys section.\\n\\nClick on Create New Secret Key.\\n\\nCreate a new API key to get your API for using ChatGPT Give your key a unique name and click Create New Key.\\n\\nNaming and Saivng the API Key Now you can copy your newly generated secret key and use it in your applications.\\n\\nCopy the API Key and use it for your applications Step 2: Set up the OpenAI API key as an environment variable in your project to ensures secure access without hardcoding the key in your code. For example, in a .env file, add the following line: OPENAI_API_KEY=your_api_key_here Step 3: In your Python script, import the necessary libraries and load the environment variable: import os from dotenv import load_dotenv import openai import langchain', metadata={'source': './LangChain-Documentation.txt'}),\n",
       " Document(page_content='load_dotenv() openai.api_key = os.getenv(\"OPENAI_API_KEY\") Importing OpenAI\\'s and LangChain\\'s libraries and environment variables Step 4: Now, you can use LangChain to interact with the OpenAI API. For example, to generate a text response using GPT-3: response = langchain.generate_text(prompt=\"What are the benefits of using LangChain? \", model=\"openai/gpt-3\") print(response) Response generation using LangChain through ChatGPT Now that you know how to set up your development environment using the OpenAI API key, we take at how you can develop apps using LangChain in the next section.\\n\\nHow to Develop Applications with LangChain LangChain is an open-source framework designed for developing applications powered by a language model.\\n\\nYou can utilize its capabilities to build powerful applications that make use of AI models like ChatGPT while integrating with external sources such as Google Drive, Notion, and Wikipedia.\\n\\nDeveloping applications with LangChain Developing applications with LangChain is a straightforward process that involves the following steps.', metadata={'source': './LangChain-Documentation.txt'}),\n",
       " Document(page_content='Define your use case: First, you need to define your use case and requirements, which will help you select the appropriate components and LLMs to use. Build the logic: Next, you can use LangChain’s flexible prompts and chains to build the logic of your application. You can also use LangChain’s code to create custom functionality tailored to your use case. Once you have built the application’s logic, you can use LangChain’s components to add specific features, such as data extraction or language translation. Set and manipulate context: Finally, you can set and manipulate context to guide your application’s behavior and improve its performance. With LangChain, you have the power to create highly customized and feature-rich applications using LLMs with ease. The above should give you a basic understanding of how to develop applications using LangChain. In the next section, we’ll explore the different applications that find extensive use cases for LangChain.\\n\\n3 Application Examples of LangChain LangChain allows you to build advanced applications using a large language model (LLM). With its flexibility, customization options, and powerful components, LangChain can be used to create a wide variety of applications across different industries.\\n\\nPython engineers going over applications of LangChain The following are some of the examples where LangChain is extensively used:\\n\\n1. Text Summarization (Data Augmented Generation) With LangChain, you can develop applications that handle text summarization tasks efficiently.\\n\\nBy leveraging powerful language models like ChatGPT, your application will be able to generate accurate and concise summaries of large texts, allowing your users to quickly grasp the main points of complex documents.\\n\\n2. Question Answering Another use case for LangChain is building applications that provide question answering capabilities.', metadata={'source': './LangChain-Documentation.txt'}),\n",
       " Document(page_content='By integrating with a large language model, your application can receive user-inputted text data and extract relevant answers from a variety of sources, such as Wikipedia, Notion, or Apify Actors. This functionality can be beneficial for users seeking quick and reliable information on different topics.\\n\\n3. Chatbots (Language Model) LangChain is a valuable tool for creating chatbots powered by language models. By taking advantage of LangChain’s framework and components, your chatbot applications can provide a more natural and engaging user experience.\\n\\nUsers can interact with your chatbots for general conversation, support inquiries, or other specific purposes, and the language model will generate context-aware responses.\\n\\nThese application examples are just a few ways in which you can utilize LangChain to build powerful and versatile applications. By understanding the strengths of language models, you can create innovative solutions that cater to the needs of your users.\\n\\nTo see an example application of building applications with Python, check the following video out:\\n\\nWhat are Integrations in LangChain? LangChain provides end-to-end chains integration to make working with various programming languages, platforms, and data sources easier for you.\\n\\nThis ensures that you can seamlessly build applications utilizing a language model in the environment of your choice.\\n\\nPossible integrations in LangChain In terms of programming languages, LangChain provides support for both JavaScript and TypeScript, you can leverage the power of LangChain in web-based and Node.js applications and take advantage of the robust type-safety features TypeScript provides.\\n\\nHere’s a short list of key integrations LangChain has to offer:\\n\\nLarge Language Models (LLMs): OpenAI, Hugging Face, Anthropic, and more.\\n\\nCloud Platforms: Azure, Amazon, Google Cloud, and other popular cloud providers\\n\\nData Sources: Google Drive, Notion, Wikipedia, Apify Actors, and more.', metadata={'source': './LangChain-Documentation.txt'}),\n",
       " Document(page_content='Data Sources: Google Drive, Notion, Wikipedia, Apify Actors, and more.\\n\\nBy utilizing these integrations, you can create more advanced and versatile applications centered around a language model.\\n\\nThis will help you develop and deploy your projects quickly and efficiently, leveraging the right tools and resources for your needs.\\n\\nAdvanced Features and Customization of LangChain LangChain offers advanced features and customization options for creating powerful applications using LLMs.\\n\\nYou can tailor your application’s behavior and build sophisticated use cases such as Generative Question-Answering (GQA) or chatbots.\\n\\nLaptop showing advanced features and customization of LangChain The following are some of the key features of LangChain:\\n\\nCustomizable prompts to suit your needs Building chain link components for advanced use cases Code customization for developing unique applications Model integration for data augmented generation and accessing high-quality language model application like text-davinci-003 Flexible components to mix and match components for specific requirements Context manipulation to set and guide context for improved accuracy and user experience With LangChain, you can create feature-rich applications that stand out from the crowd, thanks to its advanced customization options.\\n\\nTo help you take full advantage of LangChain’s features, let’s take a look at some valuable resources you could use in the next section!\\n\\nResources and Support for LangChain LangChain comes with various resources and support to help you develop powerful language model-powered applications.\\n\\nPython engineers sharing resources and support for LangChain Following are some of the key resources that you can use when working with LangChain:', metadata={'source': './LangChain-Documentation.txt'}),\n",
       " Document(page_content='AI Libraries such as OpenAI and Hugging Face for AI models External sources such as Notion, Wikipedia, and Google Drive for targeted data LangChain documentation for guides on connecting and chaining components Official Documentation GitHub Repository PyPI Package Repository Data augmentation to improve context-aware results through external data sources, indexing, and vector representations Lastly, engaging with the LangChain community and dedicated support slack channel can be beneficial if you encounter challenges or want to learn from others’ experiences. From forums to online groups, connecting with fellow developers will enrich your journey with LangChain.\\n\\nFinal Thoughts LangChain offers a comprehensive approach to developing applications powered by generative models and LLMs. By integrating core concepts from data science, developers can leverage multiple components, prompt templates, and vector databases to create innovative solutions beyond traditional metrics.\\n\\nAs technology evolves, agents involve more sophisticated elements, including chat interfaces, offering more comprehensive support in various use cases.\\n\\nWhether you’re developing chatbots, sentiment analysis tools, or any other NLP application, LangChain can help you unlock the full potential of your data. As NLP technology continues to evolve and grow in importance, platforms like LangChain will only become more valuable.\\n\\nSo, if you’re looking to stay ahead of the curve in the world of NLP, be sure to check out LangChain and see what it can do for you!', metadata={'source': './LangChain-Documentation.txt'})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6642ec22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42ebd346",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78542776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "qa = VectorDBQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", vectorstore=docsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "648eab5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' GPT-3 was released in 2020.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query1 = \"When was GPT-3 released?\"\n",
    "qa.run(query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d6eb6f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' To install LangChain, open your terminal or command prompt and enter: pip install langchain. This command installs LangChain and its required dependencies in your Python environment.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query2 = \"How would you install Langchain?\"\n",
    "qa.run(query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02ace57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This document does not provide questions and answers, so there is no answer to this question.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query3 = \"Generate me some questions from the document with answers\"\n",
    "qa.run(query3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb58167f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' LangChain can be used to create a wide variety of applications across different industries, such as text summarization, question answering, and chatbots.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query4 = \"What are the applications of Langchain?\"\n",
    "qa.run(query4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e4d798",
   "metadata": {},
   "source": [
    "# Using LLMs To Summarize Personal Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "defb037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install youtube-transcript-api\n",
    "#pip install markdownify\n",
    "#pip install tweepy\n",
    "#pip install pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04e2c4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\rasha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7365e139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "# Twitter\n",
    "import tweepy\n",
    "\n",
    "#Scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from markdownify import  markdownify as md\n",
    "\n",
    "# YouTube\n",
    "from langchain.document_loaders import YoutubeLoader\n",
    "\n",
    "#Environment Variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "947988a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY', '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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "983980d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_from_website (url):\n",
    "    \n",
    "    #Doing a try in case it doesn't work\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except:\n",
    "        # In case it doesn't work\n",
    "        print (\"Whoops, error\")\n",
    "        return\n",
    "    \n",
    "    #Put your response in a beautiful soup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # Get your text\n",
    "    \n",
    "    text = soup.get_text()\n",
    "    # Convert your html to markdown. This reduces tokens and noise\n",
    "    text = md(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adc0d320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm going to store my website data in a simple string.\n",
    "# There is likely optimization to make this better but it's a solid 80% solution\n",
    "\n",
    "website_data = \"\"\n",
    "urls = [\"https://eladgil.com/\", \"https://blog.eladgil.com/p/defensibility-and-competition\"]\n",
    "\n",
    "for url in urls:\n",
    "    text = pull_from_website (url)\n",
    "\n",
    "    website_data += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc9c4afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Elad Gil\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Welcome to Elad Gil's retro homepage!\n",
      "\n",
      " Who? I am a technology entrepreneur. LinkedIn profile is here.\n",
      "What?\n",
      "I am an investor or advisor to companies including Airbnb, Airtable, Anduril, Brex, Checkr, Coinbase, dbt Labs, Deel, Figma, Flexport, Gitlab, Gusto, Instacart, Navan, Notion, Opendoor, PagerDuty, Pinterest, Retool, Rippling, Samsara, Square, Stripe\n",
      "I am involved with AI com\n"
     ]
    }
   ],
   "source": [
    "print(website_data[:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ac48de",
   "metadata": {},
   "source": [
    "# Pulling Data from Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ce33c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling data from YouTube in text form\n",
    "def get_video_transcripts (url):\n",
    "    loader = YoutubeLoader.from_youtube_url(url, add_video_info=True)\n",
    "    documents = loader.load()\n",
    "    transcript = ' '.join([doc.page_content for doc in documents])\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8296689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a regular string to store the youtube transcript data.\n",
    "# Video selection will be important.\n",
    "#Parsing interviews is a whole other can of worms so I'm opting for one where Elad is mostly\n",
    "video_urls = ['https://www.youtube.com/watch?v=nglHX4B33_o']\n",
    "videos_text = \"\"\n",
    "\n",
    "for video_url in video_urls:\n",
    "    video_text = get_video_transcripts (video_url)\n",
    "    videos_text +=video_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ea28c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like to say that startups are an act of desperation and the desperation went out of the ecosystem over the last two or three years and we just had people showing up for the status and the money and now I think it's getting back to people who are doing it for a variety of reasons including the impa\n"
     ]
    }
   ],
   "source": [
    "print(video_text[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "798c384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_information = website_data + video_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea1e85ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d68b3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.create_documents([user_information])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b3fbf54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b681edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_prompt = \"\"\"You are a helpful AI bot that aids a user in research.\n",
    "Below is information about a person named {persons_name}.\n",
    "Information will include tweets, interview transcripts, and blog posts about {persons_name}\n",
    "Your goal is to generate interview questions that we can ask {persons_name}\n",
    "Use specifics from the research when possible\n",
    "\n",
    "% START OF INFORMATION ABOUT {persons_name}:\n",
    "{text}\n",
    "% END OF INFORMATION ABOUT (persons_name):\n",
    "\n",
    "Please respond with list of a few interview questions based on the topics above\n",
    "\n",
    "YOUR RESPONSE: \"\"\"\n",
    "map_prompt_template= PromptTemplate (template=map_prompt, input_variables=[\"text\", \"persons_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e69de0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_prompt = \"\"\"\n",
    "You are a helpful AI bot that aids a user in research.\n",
    "You will be given a list of potential interview questions that we can ask {persons_name}.\n",
    "\n",
    "Please consolidate the questions and return a list\n",
    "\n",
    "% INTERVIEW QUESTIONS\n",
    "{text}\n",
    "\"\"\"\n",
    "combine_prompt_template= PromptTemplate (template=combine_prompt, input_variables=[\"text\", \"persons_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f10293b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=.25, model_name='gpt-3.5-turbo')\n",
    "\n",
    "chain = load_summarize_chain (llm,\n",
    "                             chain_type=\"map_reduce\",\n",
    "                             map_prompt=map_prompt_template,\n",
    "                             combine_prompt=combine_prompt_template,\n",
    "                             #verbose=True\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec97482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain({\"input_documents\": docs,\n",
    "               \"persons_name\": \"Elad Gil\"\n",
    "               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "25ce6be6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidated list of interview questions for Elad Gil:\n",
      "\n",
      "1. Can you tell us more about your experience as a co-founder and CEO of Mixer Labs, and how that acquisition by Twitter impacted your career?\n",
      "2. As an investor and advisor to numerous successful companies, what criteria do you look for when deciding to invest in a company?\n",
      "3. Could you share some insights on the AI companies you are involved with, such as Character.AI, Harvey.AI, and Perplexity.AI? What potential do you see in these companies?\n",
      "4. How did your time at Google, specifically working on their mobile team and AdSense, shape your understanding of the technology industry?\n",
      "5. In your blog post titled \"Defensibility & Competition,\" you discuss the importance of defensibility in high-growth companies. Can you elaborate on this concept and provide examples of companies that have successfully achieved defensibility?\n",
      "6. As a co-founder of Color Health, what motivated you to start a company in the healthcare industry? How does it align with your previous experiences in the technology sector?\n",
      "7. With your experience in scaling companies like Twitter, what strategies do you believe are crucial for successfully scaling a company from a small team to a large organization?\n",
      "8. As an author of a book on high-growth companies, what key lessons or insights can readers expect to gain from your book? How does it differ from other books on the same topic?\n",
      "9. Can you discuss your involvement with companies like Airbnb, Airtable, and Instacart? What role do you play in their growth and success?\n",
      "10. In your opinion, what are some of the biggest challenges and opportunities in the technology industry today? How do you see these evolving in the future?\n",
      "11. In your blog post, you mentioned that most early stage startups are not very defensible. Can you provide some examples of startups that were able to establish defensibility early on and what factors contributed to their success?\n",
      "12. You discussed various forms of defensibility that startups can build over time, such as network effects, platform effects, and integrations. Can you share some examples of companies that successfully leveraged these forms of defensibility and how it impacted their growth?\n",
      "13. One of the forms of defensibility you mentioned is bundling and cross-selling products. Can you explain how this strategy can prevent competitors from gaining an edge and provide some examples of companies that have effectively utilized bundling?\n",
      "14. You mentioned that deals, such as early access to APIs or exclusive provider agreements, can create defensive moats. Can you elaborate on how these types of deals can give a company a competitive advantage and share any specific examples?\n",
      "15. In your blog post, you discussed the importance of speed as an advantage for startups. Can you explain how startups can leverage their speed to compete against incumbents and other startups? Can you provide any examples of companies that have successfully used speed as a competitive edge?\n",
      "16. You mentioned that pricing can occasionally give startups an advantage over incumbents. Can you provide some examples of startups that have used innovative pricing strategies to gain a competitive edge and how it impacted their growth?\n",
      "17. Intellectual property (IP) is often seen as a form of defensibility for hard tech or biotech companies. Can you explain how IP can protect these types of companies and share any specific examples of startups that have successfully utilized their IP as a competitive advantage?\n",
      "18. In your blog post, you mentioned the concept of a brand as a form of defensibility. Can you discuss how a strong brand can position a company as the default choice for a specific use case and provide some examples of companies that have successfully built a brand as a competitive advantage?\n",
      "19. You mentioned that most forms of defensibility take a few years to build. Can you explain why more startup founders don't just copy companies that are already successful early on in their journey? What are some of the challenges or barriers that prevent startups from being fast followers?\n",
      "20. Can you share any personal experiences or insights from your own entrepreneurial journey that relate to the topics of defensibility and competition in the startup ecosystem?\n",
      "21. Can you explain the concept of defensibility in the startup ecosystem and how it can be achieved through various means such as intellectual property, scale effects, and unique data?\n",
      "22. What are some examples of companies that have successfully built defensibility and how did they do it? Can you provide specific case studies?\n",
      "23. In your research, you mentioned that startups often face competition from other startups in the early stages and then from incumbents later on. Can you elaborate on this transition and how startups can navigate it?\n",
      "24. How important is user-centric focus in building a successful company? Can you provide examples of companies that have excelled in this aspect and how it has contributed to their success?\n",
      "25. What are some common reasons why startup founders don't simply copy successful companies and out-execute them? How does pride, perception of the market, and hiring challenges play a role in this decision?\n",
      "26. Can you discuss the role of speed in the startup ecosystem and how it can be an advantage against both incumbents and other startups? How can startups maintain a high level of execution speed consistently?\n",
      "27. You mentioned the importance of ongoing product building and expansion after the initial launch. Can you explain why this is crucial for building defensibility and how it can protect a company from being commoditized by competitors?\n",
      "28. How do you assess the aggressiveness of incumbents in a specific market and their likelihood to act against a startup? What strategies can startups employ to mitigate the risks posed by incumbents?\n",
      "29. Can you provide insights into the different forms of focus that companies can have, such as navel-gazing-centric, competition-centric, and user-centric? What are the advantages and disadvantages of each approach?\n",
      "30. In your opinion, what is the balance between serving customer needs and building defensibility? How can startups prioritize these aspects effectively to ensure long-term success?\n",
      "31. Can you share your thoughts on the importance of understanding the competitive landscape and the potential threats posed by incumbents in the early stages of a startup?\n",
      "32. How do you differentiate between a company that is too focused on internal processes and approvals, and one that is truly user-centric? What are the potential consequences of each approach?\n",
      "33. In your experience, what are some common pitfalls that founder-led companies face when it comes to competition-centric thinking? How can they overcome these challenges?\n",
      "34. Can you elaborate on the concept of defensibility and its relationship with serving customer needs? How does defensibility evolve over time, and what factors contribute to it?\n",
      "35. How do you assess the balance between building and expanding a product after launch and the vulnerability it may create for startups or incumbents to commoditize it? What strategies can companies employ to maintain defensibility?\n",
      "36. Could you provide examples of areas that have deal or licensing moats, IP protection, or pre-existing open source software that can contribute to a company's defensibility? How do these factors impact the competitive landscape?\n",
      "37. What role does a founder's bias to action play in the aggressiveness of a company? Can you share any insights on how past history of bias to action (or lack thereof) can influence a company's success?\n",
      "38. How do you approach the challenge of finding the right balance between serving customer needs and building defensibility? Are there any trade-offs that need to be considered?\n",
      "39. Can you discuss the significance of market entry or expansion by incumbents and its potential impact on the growth and survival of startups? What strategies can startups employ to navigate this challenge?\n",
      "40. Based on your experience, what advice would you give to early-stage founders who find themselves overly focused on their competitors? How can they shift their mindset to be more customer-centric?\n",
      "41. In your interview, you mentioned that startups are an act of desperation and that the ecosystem has shifted towards people doing it for a variety of reasons. Can you elaborate on what those reasons are and how they impact the startup landscape?\n",
      "42. You mentioned that 2023 will be a rough year for mid to late stage private technology companies, with potential layoffs, blow-ups, and some companies going out of business. Can you provide more insights into why you believe this will happen and what factors will contribute to it?\n",
      "43. You discussed the potential for virtual assistants that can take action and perform tasks for us. Can you share your thoughts on the timeline for the development of such assistants and the challenges that need to be overcome to make them a reality?\n",
      "44. There is a discussion about open versus closed systems in the AI space, particularly in relation to language models and image generation. Can you explain the current state of openness in these areas and the factors that influence it?\n",
      "45. The cost of training language models like GPT3 and GPT4 was mentioned. Can you provide more details on the approximate cost to train a brand new language model today and how you see this cost evolving in the future?\n",
      "46. You mentioned the potential industry structure in the AI space, comparing it to the cloud world or the semiconductor world. Can you elaborate on these comparisons and share your thoughts on how the industry might evolve in the future?\n",
      "47. You mentioned SpaceX's Starlink and Anduril as interesting companies to watch in the space and defense sectors. Can you explain why these companies stand out and what makes them unique in their respective fields?\n",
      "48. In relation to defense tech startups, you mentioned that Anduril has a broad suite of solutions and a different business model compared to traditional defense tech companies. Can you provide more insights into what sets Anduril apart and why it has been successful in the defense industry?\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "print (output['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cbadfa",
   "metadata": {},
   "source": [
    "# Question - Answering in Langchain using your own PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2701b3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f753266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"./CS-Research.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dc3bfcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/277941134\\nComputer science research: the top 100 institutions in India and in the world\\nArticle \\xa0\\xa0 in\\xa0\\xa0Scient ome trics  · August 2015\\nDOI: 10.1007/s11192-015-1612-8\\nCITATIONS\\n44READS\\n10,015\\n3 author s:\\nSome o f the author s of this public ation ar e also w orking on these r elat ed pr ojects:\\nScient o-text View pr oject\\nDocument L evel Sentiment Analysis  View pr oject\\nVivek K umar Singh\\nBanar as Hindu Univ ersity\\n202 PUBLICA TIONS \\xa0\\xa0\\xa02,459  CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nAshr af Uddin\\nSouth Asian Univ ersity\\n34 PUBLICA TIONS \\xa0\\xa0\\xa0732 CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nDavid Pint o\\nBenemérit a Univ ersidad A utónoma de Puebla\\n184 PUBLICA TIONS \\xa0\\xa0\\xa01,620  CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nAll c ontent f ollo wing this p age was uplo aded b y Ashr af Uddin  on 18 F ebruar y 2017.\\nThe user has r equest ed enhanc ement of the do wnlo aded file.', metadata={'source': './CS-Research.pdf', 'page': 0}),\n",
       " Document(page_content='1 \\n \\nTITLE  PAGE  \\n \\nComputer Science Research: The Top 100 I nstitutions in India \\nand in the W orld \\n \\n \\nAuthors:  \\n \\nVivek Kumar Singh1, Ashraf Uddin1 and David Pinto2 \\n \\n1 Department of Computer Science,  \\nSouth Asian University, New Delhi, India  \\n \\n2 Faculty of Computer Science ,  \\nBenemérita Universidad Autonóma de Puebla, Puebla, Mexico  \\n \\n \\n \\n \\nCorresponding Author and Address  \\n \\nDr Vivek Kumar Singh  \\nDepartment of Computer Science  \\nSouth Asian University  \\nAkbar Bhawan, Chanakyapuri, New Delhi -110021  \\nEmail: vivekks12@gmail.com  \\nTel: +91 -11-24195148, +91 -9971995005  \\nWeb: http://www.sau.ac.in/~vivek/   \\nhttp:// www.viveksingh.in   \\n \\n \\n \\n \\n \\n \\n \\n ', metadata={'source': './CS-Research.pdf', 'page': 1}),\n",
       " Document(page_content='2 \\n \\nComputer Science Research: The Top 100 I nstitutions in India \\nand in the W orld \\n \\nVivek Kumar Singh1, Ashraf Uddin1 and David Pinto2 \\n \\n1 Department of Computer Science,  \\nSouth Asian University, New Delhi, India  \\nvivek@cs.sau.ac.in  and mdaakib18@gmail.com  \\n2 Faculty of Computer Science ,  \\nBenemérita Universidad Autonóma de Puebla, Puebla, Mexico  \\ndpinto@cs.buap.mx   \\n \\n \\nAbstract: This paper aims to perform a detailed scientometric and text -based analysis of Computer Science \\nresearch output of the 100 most productive institutions in India and in the world. The analytical characterization \\nis based on research output data indexed in Scopus durin g the last 25 year  period  (1989 -2013). Our \\ncomputational analysis involves a two -dimensional approach involving the standard scientometric methodology \\nand text -based analysis. The scientometric characterization aims to assess Indian research in CS domain v is-à-\\nvis the world top and to bring out the similarities and differences among them. It involves analysis along \\ntraditional scientometric in dicators such as total output, citation -based impact assessment, co -authorship  \\npatterns , international collaboration  levels  etc. The text -based characterization aims to identif y the key research \\nthemes and the ir temporal trends  for the two institution sets . The experimental work is one of its kinds  and \\nperhaps the only such work that identify  characteristic similarities and differences in CS research landscape of \\nIndian institutions vis -à-vis w orld institutions . The paper presents useful analytical results and relevant \\ninferences.   \\n \\nKeywords : Computer Science  Research , India, Information Technology, Informetrics, Scientometric s. \\nJEL Classification  I23 \\n \\n1. Introduction  \\nThe Information T echnology  (IT) plays a very vital role in progress of any nation  in the modern era . The \\nInformation and Communication T echnologies (ICT) , to a large extent , are  based on research and \\ndevelopment in Computer S cience (CS). The present century has witnessed rise of knowledge economies ', metadata={'source': './CS-Research.pdf', 'page': 2}),\n",
       " Document(page_content='3 \\n \\nand nations across the world are investing more and more on the development of science and t echnology, \\nparticularl y ICT. Though, a late starter in CS domain research, India  has got more and focuses on it during \\nlast two decades  and has attained a respectable presence in the IT development sector . However, Indian \\ninstitutions are yet to attain the stage of being at for efront of knowledge creation in CS domain. In this \\ncontext, it is important to measure and assess  research competence of most productive Indian institutions \\nvis-à-vis the most productive world institutions . This paper present s our research work with this broader \\nmotivation  and presents  outcomes and inferences obtained using standard scientometric and a novel text -\\nbased analytical methodology. Our analysis involves a fairly large set of 100 most productive institutions in \\nIndia as well as in the world. The data for analysis is the CS domain research output for last 25 year period \\n(1989 -2013)  indexed in Scopus1.  \\n \\nWe have tried to do a systematic computational analysis  to characterize similarities and differences in the \\nresearch output of most productive inst itutions of India and the world. Our effort has been to present a \\ndetailed analytical characterization of CS research from most productive Indian institutions vis -à-vis the \\nmost productive institutions world wide. More precisely, we aim to answer following research questions:  \\n\\uf0b7 What are characteristic similarities and differences in CS domain research of most productive \\nIndian institutions and the most productive world institutions?   \\n\\uf0b7 What is India ’s contributi on to the total CS research worldwide and what is i ts relative impact?  \\n\\uf0b7 What major research themes are pursued by most productive Indian institutions and how does it \\nrelate to the research themes pursued in most productive world institutions?  \\n\\uf0b7 What inferences such a characterization may have for Indian inst itutions in CS domain research ?  \\nWe believe that t he results and discussion in the paper help in answering the research questions stated \\nabove  and few other related ones .   \\n \\nThe rest of the paper is organized as follows: Section 2 briefly describes some related  work . The s ection 3 \\npresents a brief overview of CS domain research in India. Section 4 describes the data collection  and the \\nsection 5 explains the methodology followed. The section 6 presents  results of scientometric indicator \\ncomputations for bo th Indian and world institutions. Section 7 present s analysis of Indian and world CS \\nresearch institution s using Exergy -based trajectory analysis. Section 8 describes the identification of \\n                                                           \\n1 http://www.scopus.com/  ', metadata={'source': './CS-Research.pdf', 'page': 3}),\n",
       " Document(page_content='4 \\n \\nresearch themes in the data and their trends. The section 9 present s a summary of the work and the major \\ninferences obtained . \\n \\n2. Related Work \\nThough, no previous work have done the kind of analytical characterization we attempted to do, we still list \\nsome past research  work focused on scientometric profiling for a country/ region and/ or a particular \\nsubject. Most of the se related research publications  are, however, limited to performing standard \\nscientometric analysis. Nevertheless, we list some of the research works that he lped us in identifying our \\nresearch questions and the comparative analysis methodology. A recent work (Fu, 2013)  studied the \\nindependent research of China and compare d the result s with the publication outputs of seven major \\nindustrialized countries. Anothe r work  (Kao, 2012 ) studied the improvement in management research in \\nTaiwan for a specific domain . Another related work  (Gupta , 2011) accessed several parameters such as total \\nresearch output, its growth, rank and global publication share, citation impact,  share of international \\ncollaborative papers of Indian CS research output during 1999 -2008.  One more recent study (Matthews , \\n2013)  tried to find typical ranges of two measures of individual productivity: number of papers and sum of \\nauthor share for physics  publications in South African universities. Another work  (De Souza , 2012)  aimed \\nto present the profile of the researchers, the pattern of scientific collaboration and the knowledge \\norganization in the area of information science in Brazil . In one of our r ecently published work  (Uddin , \\n2014 a), we tried to map the academic research  landscape of South Asian countries in volving  all disciplines. \\nAnother recent work (Uddin, 2014b ) did a similar analysis for the CS domain research in the SAARC \\nregion . Some r esearchers also dedicated their researches solely to explore the collaboration in different \\nscientific domains discovering collaboration patterns and its impact on research activities. One of such \\nworks (Tang , 2011)  analyzes the rapid growth of China in the field of nanotechnology and the rise of \\ncollaboration between China and the US in this emerging domain.  Similarly, some  other recent papers \\n(Ozel , 2012; Onyancha , 2011; Costa , 2013; Prathap , 2013; Teodorescu , 2011 ; Abramo , 2013; Viana , 2013; \\nOrtega , 2013; and Liu, 2013)  reported different aspects of collaboration , growth  and quantitative/ \\nqualitative measurements.  In most of these works, the techniques of presenting and analyzing research \\noutput vary over researchers’ need and similarly, the covered datasets are time and source dependent.  \\nThough, we learned lessons from the previous works listed here, we aimed to do a  different kind of \\nanalytical charact erization using both, the standard scientometric and a text -based computational analysis. ', metadata={'source': './CS-Research.pdf', 'page': 4}),\n",
       " Document(page_content=\"5 \\n \\nTo the best of our knowledge, no previous work aimed to do the kind of analytical characterization, we \\nreport here for the CS domain research  in India (vis-a-vis the world ).  \\n \\n3. Overview of CS Research  in India   \\nCS as an academic discipline in the world began in a systematic manner in 1950s. The world's first \\ncomputer science degree program, the Cambridge Diploma in Computer Science, began at the University of \\nCambridge Computer Laboratory in 1953. The first computer science degree program in the United States \\nwas initiated at Purdue Universit y in 19622. The now well -known department of Computer Science in \\nStanford University was founded in 19653. Thereafter, a  large number of universities in developed countries \\nstarted CS education in the period of 19 60’s. In India, CS as an academic disciplin e was first introduced in \\n1963 by Indian Institute of Technology  (IIT)  Kanpur, with the start of “Computer -related” course s and the \\nfirst “CS classroom”, though an independent academic program in CS started in 19714. The IIT Madras CS \\ndepartment started in  19735, though initially as Computer center. Similarly, formal CS department started in \\nIIT Kharagpur in 19806 and IIT Bombay in 19827, in continuation to their initial efforts at teaching \\ncomputing courses. The department of Computer Science and Automatio n (CSA)8 at Indian Institute of \\nScience (I ISc) Bangalore started in 1969. It was originally called the “School of Automation” and continued \\nto be known with this name till the mid -eighties. In the university system, Jadavpur University started a \\npostgradua te diploma in CS in 1968, a first of its kind. A formal department of CS was carved out of \\ntrifurcation of the ECTE department in 19889. The  (Indian Statistical Institute)  ISI Calcutta started a two \\nyear M. Tech. program in CS in 1981, perhaps first such postgraduate program of its kind10. By the end of \\n1980s, many prominent institutions started academic programs/ departments in CS. However, in the early \\nperiod, the major focus was on education, training and manpower development. Research activity in CS \\nstarted to grow only in 1990s. The last two decades have seen CS research gaining momentum, with \\nestablishment of CS departments in all major universities/ institutions and establ ishment of specialized \\ninstitutions for Information Technology (IT) teaching and research. Some of these new specialized IT \\n                                                           \\n2 http://en.wikipedia.org/wiki/Computer_science  \\n3 http://cs.stanford.edu/  \\n4 http://www.cse.iitk.ac.in/dept/index.html  \\n5 http://www.cse.iitm.ac.in/  \\n6 http://cse.iitkgp.ac.in/  \\n7 http://www.cse.iitb.ac.in/page17  \\n8 http://www.csa.iisc.ernet.in/aboutus/aboutus.php  \\n9 http://www.jaduniv.edu.in/htdocs/view_department.php?deptid=59  \\n10 http://www.isical.ac.in/~mtechcs/  \", metadata={'source': './CS-Research.pdf', 'page': 5}),\n",
       " Document(page_content='6 \\n \\ninstitutions have gained a very respectable presence in CS research in a very short span of time. Some of the \\nmajor IT companies hav e also started their research laboratories in India during the last 2 -3 decades, such as \\nIBM Research in 1988 and Microsoft Research in 2005. Some applied research in CS domain is now also \\ncarried out at various government laboratories/ organizations, such  as CSIR11, DRDO12, ISRO13 etc. \\n \\nIn order to have a more informed picture of the current status of CS research in India, we have collected \\ndata for  CS domain research output of all institutions in India , for the 25 year period from 1989 to 2013 , \\nfrom the Scop us database . This period happens to be the period of actual growth in CS research in India. \\nWe plot  the year-wise proportionate contribution of India  to the total CS domain research worldwide in \\nFigure 1 . We see that India’s share to the total CS research output of the world is increasing in general, \\nexcept in few years . In terms of percentage contribution, it increased from 1.88% in 1989 to 4.95% in 2013 . \\nThe rate of growth is more clearly visible from 2000-01. Also, computing the rates of growth of CS \\nresearch in India and the total world tells us that India ’s average rate of growth is higher than the world . \\n \\n4. Data Collection  \\nWe have collected data of CS research output for a period of 25 years (1989 -2013)  from Scopus, a well -\\nknown bibliometric database . A total of 2 ,876,512 publication records are (were)  found for the period 1989 -\\n2013  for the whole world , where India contributes 84,385 ( about 2.93%) research papers , as on March \\n2014 . We collected data ins titution -wise for 100 most productive institutions from  India (referred to as \\nI100) and the world  (referred to as W 100). Our collection, though  not exhaustive , is a good representative \\nof research output data . The collected representative data covers 846,527 846,526 records ( about 29.43%  \\n29.6%) of the world CS research output  and 59,682 59,619  records ( 70.73%  71%) of the total Indian CS  \\nresearch output . Out of a total of 61,502 records in Scopus for  Indian CS  research output  (I100) , 1,314 \\nentries  have missing year value and about 506 duplicate entries , which leave  unique records as 59,682. Out \\nof a total 60,119 records in Scopus for Indian CS research output (I100), duplicate records were removed, \\nwhich leave 59 ,619 unique records. Similarly, for world universities  in CS research (W100), 846,527  \\n846,526  are unique records as against 924,575 records originally found in data .  In addition to CS domain \\nresearch output of I100 and W100, we also collected some related statistics for India and world, such as \\n                                                           \\n11 http://www.csir.res.in/  \\n12 www.drdo.gov.in  \\n13 http://www.isro.org/  ', metadata={'source': './CS-Research.pdf', 'page': 6}),\n",
       " Document(page_content='7 \\n \\nGross Expenditure on Research and Development (GERD), Researchers per million people etc. The table 1  \\nshows these values to establish a broader background perspective for our analytical characterization.  \\n \\n5. Methodology  \\nOur analytical characterization methodology is primarily a two -dimensional ap proach, comprising of a \\nstandard scientometric analysis and a computational text analysis. First, w e perform a scientometric \\ncharacterization along the six main indicators, namely Total Publication (TP), Total C itations (TC), \\nAverage Citation Per Paper (ACPP), HiCP (Highly Cited Papers), Internationally Collaborated P apers (ICP) \\nand the cited percentage . Out of these, o nly TP i s a primary indicator, and all other secondary indicators are \\ncomputed programmatically  from the data.  We have computed these indicators for all the institutions in \\nboth the sets. Second major part of our analysis is to characterize the major research themes pursued and \\nadvanced by the institutions in the set. For this task, we have processe d the entire data to classify every \\nresearch output in one (or more) of the 11 major thematic areas in CS research, as illustrated in Appendix. \\nThis thematic mapping is more informative than the subcategory labels used by the Scopus database  and is \\nextende d from a recent previous work (Uddin & Singh, 2015) . For classifying a paper to belong to a \\nthematic area, its ‘author keyword’, ‘paper title’ and ‘abstract’ fields are analyzed. A paper is assigned a \\nthematic class which has substantial match of keywords with the predefined thematic classes. After \\nattributing thematic areas to each paper, we measured the thematic area strength of all the institutions and \\nidentified leading institutions in a particular thematic area  (Thematic trend, we have done for I100 &  W100 \\nas a whole but not institution -wise). This has been done for the two sets, I100 and W100. While, the \\nscientometric analysis helps us in analytical and comparative characterization of research competitiveness \\nof I100 and W100 sets, t he text -based comp utational analysis helps us in identifying leading research \\nthemes pursued by institutions in the two sets and the similarities and differences  among them .   \\n \\n6. Scientometric Indicator Computations  \\nWe would first present the computational results of analytic al characterization using scientometric \\nindicators. The results compare and characterize the two sets, I100 and W100, along different indicators as \\nsummarized in the four subsections below.   \\n \\n6.1 Research Output  ', metadata={'source': './CS-Research.pdf', 'page': 7}),\n",
       " Document(page_content='8 \\n \\nWe first tried to do a detailed indicator -based comparison of institutions in I 100 and W100. Before, we \\npresent the results;  it would be relevant to mention here that no Indian institution figures in the W100 set of \\n100 most productive institutions worldwide . The relative rank on product ivity of Indian institutions can be \\nunderstood from the fact that total 25 year period CS research output of 100th institution (University College \\nLondon) in W100 is 5,747 whereas , the output of the two top ranking Indian institutions, namely Indian \\nInstitute of Technology, Kharagpur and Indian Institute of Science, Bangalore are 3,514 and 3,506, \\nrespectively. The most productive Indian institution has output levels below 150th rank institution in W100. \\nIt may also be worth mention ing that in a  recently published ranking by ARWU14, only two Indian \\ninstitutions, “Indian Statistical Institute” and “Indian Institute of Science”, are placed in the top 200 list, \\nunder  CS subject category.  We present the detailed statistics of scientometric indicator -based comparative \\nassessment in tables 2 and 3. The table 2 present s comparative figures for the sets, I100 and W100, as a \\nwhole. Form the tables; w e observe that there is a significant difference among indicators like ACPP (I100 \\naverage being 2.66 and W100 average 9.37), HiCP (average value of 60 for I100 and 855 for W100), ICP \\n(110 for I100 as against 2419 for W100) and cited percentage (39.33% for I100 and 58.91% for W100). \\nThe table 3 presents values of various scien tometric indicators for 20 most productive institutions in I100 \\nand W100, for a more detailed comparison.    \\n \\n6.2 Co -authorship Pattern s \\nThe second important aspect we addressed is about the c o-authorship and collaboration patterns seen in the \\nCS research in top Indian institutions and the top institutions worldwide. The authorship pattern for research \\npapers has known to have effect on their overall impact. A paper with multiple (more than one) authors is \\nthe joint contribution of two or more authors  and has inputs from different people/ groups. Higher multi -\\nauthored papers are an indicator for higher interdisciplinary research and/ or higher level of collaboration \\nbetween researchers at national or interna tional level. Research projects involving bigger groups also result \\nin higher multi -authored papers. From the data, we observed the co-authorship  pattern s for India, and found \\nthat about 39.4% of the total CS research outputs of I100 involve two authors and about 32% with three \\nauthors. Only  about 5% of the output is by a single author , indicating that about 95% of the total CS output \\ninvolves some form of collaboration. The co -authorship pattern for the W100 , however, shows different \\nscenario  where the co -authorship distribution is less skewed (0.91) than that of Indian CS co -authorship \\n                                                           \\n14 http://www.shanghairanking.com/SubjectCS2014.html  ', metadata={'source': './CS-Research.pdf', 'page': 8}),\n",
       " Document(page_content='9 \\n \\ndistribution (1.51). The Figure s 2(a) and 2(b) show year -wise trends of co -authorship patterns f or the \\ncollected data. There is a clear trend towards higher co llaboration between researchers, as measured by \\nmultiple authors in more and more research papers. In the most recent year, about 50% of the total CS \\nresearch for W100  is with three or more authors,  while it is about 30% for the I100.   \\n \\n6.3 International Collaboration Patterns  \\nAfter observing a higher proportion of multi -authored papers, we aimed to measure the types of \\ncollaboration patterns as national or international. Higher international collaboration is not only an indicator \\nof multi -national collabo ration but also shows maturity and international nature of a discipline. A study  \\n(Smith 1958)  was perhaps the first work on collaboration and it propose d that collaborative papers can be \\nused as a proxy measure of collaboration  among researchers.  In another work, Glanzel  (2001)  show ed that \\ninternational co -authorship, on average, results  in publications with higher citation rates than purely \\ndomestic papers. Through computational analysis, we found  that 95.5%  of the I100 are co-authored  (with \\naverage co -authorship value as 2.92) , whereas 93.5%  of the W100  are co-authored  (but average co -\\nauthorship value as 3.41) . The average co -authorship for W100  is higher, an indicator of higher level of \\ncollaboration . The Figure 3  shows collaboration patterns for outputs of I100 and W100 . We observe that \\nI100 has 25% of the collaborated papers involving international collaboration as against 30% value for \\nW100 . We also identified the top collaborating countries by Indian authors. The Table 2 shows the list of \\ntop 20 countries  having highest collaboration in I100 output during the 25 year period. The United States  of \\nAmerica  contributes largest share of I100’s international collaboration ( with 4316  research papers) followed \\nby Singapore  (849 research papers) and  Canada ( 801 research papers ). The W100  data shows higher \\ninternational collaborative research papers, including multi -country collaboration outputs.  \\n \\n6.4 Citation -based Impact  Assessment  \\nAn independent report by Thompson Reuters showed that India had about 0.52% of its national output (all \\ndisciplines) in the worldwide HiCP list in 2011  (Thompson Reuters Report on The Research and Innovation \\nPerformance of G20, March 2014 ). It is well acce pted that s olely counting number of research publications \\nmay not be the best method  to measure the scientific research productivity  and usefulness . It focuses \\nprim arily on the output quantity and not on the quality as measured through impact/ productivity . It would \\nnaturally be unfair to treat two research papers, one with very high citation count and the other with low or ', metadata={'source': './CS-Research.pdf', 'page': 9}),\n",
       " Document(page_content='10 \\n \\nno citation, as equally useful. On the other hand, a research paper with higher citation is considered more \\neffective, useful and productive.    Citation count is considered an effective measure of productivity and \\ninfluence of a research paper. We have extracted total citations of each research paper in the I100 and \\nW100  data and also identif ied the top cited papers  (top 10% most cit ed papers)  in each group for each of the \\n25 years. We track the institution information for all such records and look for top contributing institutions \\nto the set of highly cited (top 10%) publications. The figure 4(a) shows the number of collaborated pape rs \\namong the top 10% highly cited papers  in I100. We find that t otal of 1797 papers (app roximately  30% \\namong the top 10% cited papers ) are collaborated internationally.  After an assessment of relationship \\nbetween collaboration and citation -impact, we moved to identify the top institutions in I100 with highest \\nproportions of top 10% highly cited papers  in I100. The  figure 4(b)  shows top five institutions for each year \\nchronologically. The vertical axis represents the contribution in percentage to the top10% cited papers in \\nthe particular year. The figure clearly shows that initially only certain selected institutions contributed to th e \\nelite set of papers and grabbed maximum of the set. However, o ver the period of time other institutions also \\ncontributed to the top 10% highly cited papers, an indicator of quality research output being generated from \\nmore and more institutions. On an av erage, 12 institutions from India are the most frequent  contribut ors to \\nthe top cited papers in I100 set. The Indian Institute of Science (IIS) showed almost omnipresence  in all the \\nyears , except 1989 , indicating most consistent qualitative output . The Indian Institute of Technology, \\nKharagpur (IITK) , Indian Institute of Technology, Delhi (IITD) and Indian Statistical Institute, Kolkata \\n(ISIK) are few other frequent names in the list. We also measured the proportion of CS research output in \\nI100 and W100  that remains un -cited. The figure 4(c) shows the percentage of cited and un -cited papers  for \\nboth I100 and W100 , shown  over five consecutive chronological blocks  of five years each. The problematic \\nindication observed is that the percentage of papers that are cited is decreasing over the time. This may be \\ndue to smaller citation window availability or possibly with higher amount research output, a large part of \\nwhich is not that useful/ productive. On a comparison between I100 and W100  data, we observe that the \\ncorresponding cited figures (in percentage) for first two blocks are almost same but the values for W100  in \\nrecent three blocks are higher, implying low  immediacy index  for CS research output from India . \\n \\n \\n7. Performance based on  Trajectory A nalysis  \\nA recent paper (Nishy 2012) proposed a n exergy rank based on a thermodynamic analogy . The exergy \\nindicator (referred as X) is a multiplicative product of quality and quantity of a scientist’s or research ', metadata={'source': './CS-Research.pdf', 'page': 10}),\n",
       " Document(page_content='11 \\n \\ngroup’s performance . The measure is derived from primary/ secondary indicators like impact, citations and \\nnumber of papers . The proposed system tries to define a single meaningful indicator that combines both, the \\nquantit y (number of papers published , P) and the quality (measured as impact , i=C/P, where C is citation \\ncount ) aspects. A quality proxy, called exergy is defined as X=(C/P)*C . The values of i and P or i and C \\ncan be shown as  trajector ies on two -dimensional plot with respect to  time (known as iPX and iCX \\napproaches, respectively) . Both the iCX (the contour lines for X=iC ) and iPX (the contour lines for X=i2P) \\ncan be chosen for two dimensional mapping of the information. The iPX approach is more intuitive as it \\nshows the direct relation between quantity ( P) and quality ( i) which is of our interest but in iCX approach \\noutput P is hidden and does not directly reflect the quantity ( P). We have used the exergy measure to \\ncompute quantity -quality composite rank for some selected institutions in I100 and W 100.  \\n \\nWe have measured th e research performance of the top 5 Indian institutions in I100 and plotted them with \\nthe top 5  institutions in W100  list based on their TP value . This is done  primarily to compare the relative \\nperformance of Indian institutions vis -à-vis the institutions in world top 100. Unfortunately, no Indian \\ninstitution appears in the W100  list. The figure 8(a) displays  the exergy values for the selected institutions . \\nHere, the X-axis represents the time in year and Y-axis denotes the obtained exerg y score in that particular \\nyear. Similarly, two sets of institutions were selected based on ACPP and on HiCP values. Selecting \\ninstitutions on the values of different indicators help us to see the performance variability of institutions  \\nleading on different indicators’ scale. Figures 8(b) and 8(c)  shows the performance in exergy for institutions \\nselected based on ACPP and HiCP, respectively.  All the plots are made f or eight 5 year rolling windows , \\nfrom 2001 -2005 to 2008 -2012  to see the pe rformance in the following 6th year (2006 -2013) . We see that all \\nselected Indian institutions ’ performances  are below all selected W100 institutions’ performances , a result \\nthat needs serious thought. Among the top Indian institutions  in I100, most of them  are IITs . All the exergy \\ngraphs show  that in terms of performance (quantity -quality) measure Indian institutions are far behind than \\nthat of W100  institutions. The important thing here to mention is that we did not consider the academic \\ninfrastructure suc h as number of faculties, active researchers etc in the context . The data and computed \\nvalues are shown in supplementary table 5(a-c). The supplementary table s show the paper published ( P) by \\nthe leading institutions over a five year publication window and  citations ( C) obtained in the next year for \\neach publication window. These values are used to compute the impact ( i=C/P ) and the exergy ( X=C2/P). \\n ', metadata={'source': './CS-Research.pdf', 'page': 11}),\n",
       " Document(page_content='12 \\n \\n8. Identifying Research T hemes in Output  \\nIn addition to the scientometric analysis, we also performed a text -based analysis of the data to identify \\nmajor research topics/ themes and their variations with respect to time. We used the burst detection \\nalgorithm (Kleinberg 2003)  for this task . We app lied the algorithm on the “indexed keyword ” field of our \\ndata set  for the entire 25 year period. The burst detection measures the keyword weights which is a function \\nof the occurrence  frequency and the time span of the keyword.  The Science of Science (Sci2 )15 was used for \\ntemporal analysis (Burst Detection).   A keyword with a heavy weight indicates that the topic was \\nresearched frequently for a significant period of time. The figure s 6(a) and 6(b) show keyword density \\nplots, based on their corresponding weight s, for I100 and W100  data, respectively. For the visualization \\npart, we used VOSviewer16 reflecting the weights of corresponding keyword s. We can see that “Computer \\nSimulation” and “Mathematical Models” are present in leading positions in both figures. Similarly \\n“Problem Solving” appear s in both plots . However, the W100  plot shows a significan ce of topics like  \\n“Algorithms”, “Approximation Theor y”, “Network Protocols” and “ Computational Complexity” ; where the \\nI100 plots show significance of topics like “Computer Networks”, “Information Technology”, \\n“Communication” and “Computational Methods” , for the entire 25 year period considered. In \\nsupplemen tary figures 6 (c ) to 6(g), we show the tag cloud plot visualization of the major research themes \\nfor the I -Top10  in the left and W100  in the right .   The tag -cloud for the su b-period 1989 -1993 shows that \\n“Algorithm”, “M athematical Models”, “Computer S imulation” were  the leading topics in I100, whereas \\nW100  had frequent occurrence of “Algorithm”, “Computer S imulation ”, “Optimization” and “Image \\nProcessing” . In the 1994 -1998  block , “Algorithms”, “Communication”, “O ptimizat ion”, “Information \\nTechnology” &  “Artificial I ntelligence” were the top topics  in I100, whereas  “Mathematical M odels” & \\n“Computer S imulation” dominated in W100 . In 1999 -2003, “Mathematical M odels” again took the leading \\nposition  followed by “A lgorithms  for I100 and “Mathematical Models ” & “Optimization ” dominated in \\nW100 . In 2004 -2008, “Mathematical M odels” became more  significant as compared to “Algorithm”  for \\nI100 and in W100 , “Problem S olving” & “Optimization” were prominent . In 2009 -2013, we can see a slight \\nchange from previous block’s trend s, as  “Computer Simulation” & “A lgorithms” appeared as major \\nresearch themes for I100, whereas W100  shows a variation including “O ptimization”, “ Artificial \\nIntelligence” & “Signal P rocessing” . In general, “Algorithm” , “Computer S imulation”  & “Mathematical \\n                                                           \\n15 https://sci2.cns.iu.edu/user/index.php  \\n16 http://www.vosviewer.com/  ', metadata={'source': './CS-Research.pdf', 'page': 12}),\n",
       " Document(page_content='13 \\n \\nModels”  are prominent research themes i n both I100 & W100  data. The W100  data also shows  \\n“optimization” as a frequent research t heme .   \\n \\n9. Summary and Conclusion  \\nThe paper  reports our results on scientometric, network -theoretic and text -based analysis of CS research in \\nmajor institutions in India ( I100 as representative sample) and in the world ( W100  as representative sample) \\nduring the last 25 year period (1989 -2013). The analytical results present  measurements the characteristic \\nsimilarities and differences between I100 and W100 showing primary and secondary indicators of CS \\nresearch , such as absolute and comparative growth , collaboration patterns, year-wise citation -based impact \\nassessment  etc. We have also att empted to show the contribution of Indian institutions to world CS output \\nand the impact of Indian CS output . The Quality -Quantity Exergy performance measures were shown and \\ndiscussed for top institutions from I100 and W100 . Finally , we report outcome of r esearch theme trend \\nmapping through a text -based analysis  of the data. A year -block wise temporal trend  identification of \\nresearch theme is done along with burst detection of CS research output data and visualized graphically.  \\n \\nThe results found indicate t hat India has a lot to enhance it research activities with quality. Although India \\nmaintained the same trends in CS research but the quality research is still lacking. The results report \\nanalysis of a substantial period of 25 years and can be used in many ways :  to take a look at CS research in \\nIndia vis -à-vis top ranking world institutions;  to formulate polic ies for promoting research and enhancing \\nquality output ; to help a student selecting an institution for his/her research ; and other academic/ scientific \\npurposes.   \\n \\nAcknowledgement  \\nThis work is supported by research grants from Department of Science and Technology, Government of India \\n(Grant: INT/MEXICO/P -13/2012) and University Grants Commission of India (Grant: F. No. 41 -624/ \\n2012(SR)).  \\n \\nReferences  \\nAbramo, G., D’Angelo, C.A.  & Murgia, G. (2013). The collaboration behaviors of scientists in Italy: A \\nfield level an alysis. Journal of Informetrics , 7(2), 442 -454.  \\nCosta, B.M.G., Pedro, E.S.  & Macedo, G.R. (2013). Scientific c ollaboration in biotechnology: the case of \\nthe northeast region in Brazil. Scientometrics, 95(2), 571 –592. ', metadata={'source': './CS-Research.pdf', 'page': 13}),\n",
       " Document(page_content='14 \\n \\nDe Souza, C.G. & Ferreira, M.L. A. (2012).  Researchers profile, co -authorship pattern and knowledge \\norganization in information science in Brazil. Scientometrics, 95(2), 673 –687. \\nFu, H.Z, & Ho, Y.S. (2013). Independent research of China in Science Citation Index Expanded during \\n1980 –2011. Journal of Informetrics, 7(1), 210 -222. \\nGlänzel, W. (2001). National characteristics in international scientific co -authorship relations. \\nScientometrics, 51(1), 69 –115. \\nGupta, B.M., Kshitij, A.  & Verma, C. (2011). Mapping of Indian computer science research output , 1999 –\\n2008. Scientometrics, 86(2), 261 –283. \\nKao, C., Liu, S. &  Pao, H. (2012). Assessing improvement in management research in Taiwan. \\nScientometrics, 92(1), 75 –87. \\nKleinberg, J. (2003). Bursty and Hi erarchical Structure in Streams.  Data Mining and Knowle dge Discovery, \\n7, 373 –397. \\nLiu, Y., Rousseau, R.  & Guns., R. (2013). A layered framework to study collaboration as a form of \\nknowledge sharing and diffusion. Journal of Informetrics, 7(3), 651 -664. \\nMa, R.., Ni, C.  & Q iu, J. (2008). Scientific research competitiveness of world universities in computer \\nscience. Scientometrics, 76(2), 245 –260. \\nMatthews, A.P. (2013). Physics publication productivity in South African universities. Scientometrics. \\n95(1), 69 –86. \\nNishy, P., Panwa r, Y., Prasad, S., Mandal, G.K.  & Prathap, G. (2012). An impact -citations -exergy (iCX) \\ntrajectory analysis of leading research institutions in India. Scientometrics, 91(1), 245 -251. \\nOnyancha O.B.  & Maluleka, J.R. (2011). Knowledge production through collaborative research in sub -\\nSaharan Africa: how much do countries contribute to each other’s knowledge output and citation impact?. \\nScientometrics, 87(2), 315 –336. \\nOrtega, J.L.  & Aguillo, I.F. (2013). Institutional and country collaboration in an online service of scientific \\nprofiles: Google  Scholar Citations. Journal of Informetrics, 7(2), 394 -403. \\nOzel, B. (2012). Collaboration structure and knowledge diffusion in Turkish management academia. \\nScientometrics, 93(1), 183 –206. \\nPrathap, G. (2013). Second order indicators for evaluating internat ional scientific collaboration. \\nScientometrics, 95(2), 563 –570.  \\nSmith, M. (1958). The trend toward s multiple authorship in psychology. American Psychologist, 13(10), \\n596–599. \\nTang, L.  & Shapira, P. (2011). China –US scientific collaboration in nanotechnolo gy: patterns and \\ndynamics. Scientometrics, 88(1), 1 –16. \\nTeodorescu, D.  & Andrei, T. (2011). The growth of international collaboration in East European scholarly \\ncommunities: a bibliometric analysis of journal articles published between 1989 and 2009. Scien tometrics, \\n89(2),  711–722. \\nUddin, A.  & Singh, V.K. (2014). Mapping the c ompute r science research in SAARC c ountries. IETE \\nTechnical Review, 31(4), 287-296.  \\nUddin, A.  & Singh, V.K. (2014).  Measuring research output and collaboration in South Asian countri es. \\nCurrent Science , 107(1), 31 -38. \\nUddin, A. & Singh, V.K. (2015). A Quantity -Quality Composite Ranking of Indian Institutions in \\nComputer Science Research. IETE Technical Review  (forthcoming) DOI: \\nhttp://dx.doi.org/10.1080/02564602.2015.1010614  ', metadata={'source': './CS-Research.pdf', 'page': 14}),\n",
       " Document(page_content='15 \\n \\nViana , M.P., Amancio, D .R. & Costa, L.F. (2013). On time -varying collaboration networks. Journal of \\nInformetrics, 7(2), 371 -378. \\nView publication stats', metadata={'source': './CS-Research.pdf', 'page': 15})]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea8fabf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "chain = load_qa_chain (llm=OpenAI(), chain_type=\"map_reduce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a92ef28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The theme of this research paper is time-varying collaboration networks.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query1 = \"What is the theme of this research paper?\"\n",
    "chain.run(input_documents=documents, question=query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78237ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This research paper aims to answer questions about the characteristics similarities and differences between I100 and W100, the contribution of Indian institutions to world CS output, the impact of Indian CS output, Quality-Quantity Exergy performance measures for top institutions from I100 and W100, collaboration patterns, international collaboration, the top collaborating countries by Indian authors, the total citations of research papers in the I100 and W100 data, the top contributing institutions to the set of highly cited papers, and the proportion of CS research output that remains uncited.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query2 = \"What kind of questions does this research paper aim to answer?\"\n",
    "chain.run(input_documents=documents, question=query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bb03dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
